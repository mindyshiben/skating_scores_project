{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d1bbc0",
   "metadata": {},
   "source": [
    "# <center>Skating Scores Project<center>\n",
    "\n",
    "<div>\n",
    "<img src=\"oly_rings.jpeg\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "### Introduction: \n",
    "\n",
    "   Historically, figure skating has been a sport in which the United States has greatly excelled in the Olympic Winter Games. Sports that are judged on both technical merit and artistic expression are challenging to judge objectively and figure skating is no exception. In 2004, the previous highly subjective figure skating scoring system was replaced with the International Judging System(IJS) which takes into account the minutiae of every skating program awarding a specific point value based on multiple calculations. Following this change, the United States has seen a drastic decrease in international accomplishment for women skaters representing the USA. \n",
    " \n",
    "   The recent 2022 Olympic winter games in Beijing marks 4 consecutive Olympics in which the US women have not been awarded a medal. Many critics of the current state of international figure skating suggest that the medal drought is directly related to Russian dominance in women's figure skating. Russian figure skating has been under scrutiny for their questionable training tactics and with a recently doping scandal at the 2022 Beijing Olympics, it's more than reasonable for all other skating federations to reject Russian figure skating training tactics and put the wellbeing of athletes ahead of competitive victories However, can the 15 year medal drought be completed contributed to this? \n",
    "\n",
    "   In the four most recent Winter Olympic Games, at least one of the women figure skating medals has gone to an athlete from Japan, South Korea, Italy, or Canada. It's also worth noting that the United States is continuing to excel greatly in most figure skating disciplines (especially mens and ice dancing). This project is a data-driven analysis of this project in which I explore trends that may offer insights to improve US women's figure skating scores at the Olympic Games. \n",
    "   \n",
    "\n",
    "### Project Goals:\n",
    "\n",
    "- Construct a machine learning regression model that improves predicted Olympic scores of women figure skaters under the International Judging System (implemented in 2004).\n",
    "- Find the key drivers of Olympic event scores by analyzing competition data of athletes prior to their Olympic performances.\n",
    "- Empower US figure skating athletes and coaches with information that may lead to positive training modifications.\n",
    "- Thoroughly document the process and key findings.\n",
    "- Prove the potentiality of utilizing the data science pipeline to better the sport of figure skating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce731a90",
   "metadata": {},
   "source": [
    "### Summary of Findings & Recommendations:\n",
    "\n",
    "- My analysis indicates that the top drivers of Olympic Scores are:\n",
    "     > - Athlete's 4 year international competitive history preceding the Olympics\n",
    "     > - Short Program Event Scores (components and elements)\n",
    "     > - Free Program Event Scores (components and elements)\n",
    "     > - Event placements\n",
    "     > - competitive season\n",
    "\n",
    "- My data exploration revealed that USA athletes' scores are lower than desired due to :\n",
    "     > - USA athletes have a lower margin of score improvement over the last 15 years compared to non-USA athletes\n",
    "     > - The elements portion of free program shows the worst margin of improvement for USA athletes \n",
    "     > - USA athletes still slightly outscore non-USA athletes in the components score, but if the trend over the last 15 years continues, USA athletes may fall behind in this category as well\n",
    "     > - USA athletes' element scores seem to be more problematic in the free program. Because the free program is longer than the short program, lack of athletic endurance is one possible explanation to explain this discrepancy.\n",
    "\n",
    "- Interestingly, the skater's 4 year average amount of technical jumping errors did not seem to be a factor contributing to Olympic scores. \n",
    "\n",
    "- I built and trained a Generalized Linear Model(Tweedie Regressor) which is able to improve baseline predicted Olympic scores by approximately 50%.\n",
    " \n",
    "- I can recommend employing this new model with reasonable confidence.\n",
    "\n",
    "- I believe this project demonstrates great promise for the use of data science in improving training strategies and competition outcomes in US Figure Skating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15771d96",
   "metadata": {},
   "source": [
    "### Data Acquisition & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae84149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import acquire\n",
    "import prepare\n",
    "import explore\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "pd.options.display.max_seq_items = 2000\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.core import display as ICD\n",
    "import textwrap\n",
    "import ipywidgets as widgets\n",
    "from traitlets import Unicode, Dict\n",
    "from pandas_profiling import ProfileReport\n",
    "from IPython.core import display as ICD\n",
    "from IPython.display import IFrame, display, HTML\n",
    "import termcolor\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4808e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire.get_competition_data()\n",
    "# this is a user-defined function in acquire.py that pulls in selected data from skatingscores.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d35bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1860 entries, 0 to 1859\n",
      "Data columns (total 41 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   1860 non-null   int64  \n",
      " 1   Skater       1860 non-null   object \n",
      " 2   Nat_x        1860 non-null   object \n",
      " 3   SP           1103 non-null   object \n",
      " 4   SP.1         1860 non-null   float64\n",
      " 5   SP.2         1860 non-null   float64\n",
      " 6   FS           1065 non-null   object \n",
      " 7   FS.1         1858 non-null   float64\n",
      " 8   FS.2         1858 non-null   float64\n",
      " 9   Total        1085 non-null   object \n",
      " 10  Total.1      1860 non-null   object \n",
      " 11  season_x     1860 non-null   int64  \n",
      " 12  skater_name  1860 non-null   object \n",
      " 13  first_name   1860 non-null   object \n",
      " 14  #_x          1860 non-null   float64\n",
      " 15  Nat_y        1860 non-null   object \n",
      " 16  Combo Jump   1860 non-null   object \n",
      " 17  Solo Jump    1859 non-null   object \n",
      " 18  Axel         1860 non-null   object \n",
      " 19  TES_x        1860 non-null   float64\n",
      " 20  TES.1_x      1860 non-null   int64  \n",
      " 21  PCS_x        1860 non-null   float64\n",
      " 22  PCS.1_x      1860 non-null   int64  \n",
      " 23  TSS_x        1860 non-null   object \n",
      " 24  season_y     1860 non-null   int64  \n",
      " 25  #_y          1860 non-null   float64\n",
      " 26  Nat          1860 non-null   object \n",
      " 27  Elements     1860 non-null   object \n",
      " 28  TES_y        1860 non-null   float64\n",
      " 29  TES.1_y      1860 non-null   int64  \n",
      " 30  PCS_y        1860 non-null   float64\n",
      " 31  PCS.1_y      1860 non-null   int64  \n",
      " 32  TSS_y        1860 non-null   object \n",
      " 33  season       1860 non-null   int64  \n",
      " 34  event        1860 non-null   object \n",
      " 35  QA           24 non-null     float64\n",
      " 36  QA.1         24 non-null     float64\n",
      " 37  QB           24 non-null     float64\n",
      " 38  QB.1         24 non-null     float64\n",
      " 39  PR           18 non-null     float64\n",
      " 40  PR.1         18 non-null     float64\n",
      "dtypes: float64(16), int64(8), object(17)\n",
      "memory usage: 595.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# shows a snapshot of all data/columns that may potentially be used prior to data wrangling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e679c0",
   "metadata": {},
   "source": [
    "### Initial Data - \n",
    "I strategically acquired data on international-level women figure skaters since 2004. In the next steps, I will label columns much more clearly so those without specific domain knowledge will be able to understand this analysis much easier. TES, PCS, TSS, etc. are abbreviated parts of the skating score and as I acquired and joined the data together, we can see that there are many duplicate columns. Because the target variable is athletes' final Olympic score (\"oly_event_score\"), I am filtering out all records that do not belong to an Olympian. After this, there are 102 total records. One record represents a skater's olympic results from one of the five Winter Olympic Games between 2006-2022 and information about that skater's international competitive history the 4 years preceding said Olympics. It's important to note that there will be duplicate skater names in the database as some skaters have performed at more than one Olympics. \n",
    " \n",
    "Only major international events are included at this time as these are likely to be the most representative of how a skater may perform at the Olympics considering the high pressure environment. It is certainly possible to expand on this exploration and modeling process in the future by adding skaters' scores from national level competitions and additional international events. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a321b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare.prepare_competition_data(df)\n",
    "#user-defined function which wrangles and cleans data optimally for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "#displays overview of the prepared dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d4172",
   "metadata": {},
   "source": [
    "### Profile Report\n",
    "\n",
    "[Profile Report](./profile.html)\n",
    "\n",
    "- This profile report is an in-depth analysis of all variables included in the dataframe. This is included to offer full transparency of the project data and process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1218c",
   "metadata": {},
   "source": [
    "### In this project, events included are:\n",
    "\n",
    "- Grand Prix Qualifiers (America, Canada, France, Japan, Russia, China)\n",
    "- Grand Prix Final\n",
    "- World Championships (because the World Championships take place after the Olympics in a given season, the world championship scores are included as taking place the season after they do. \n",
    "- Olympic Winter Games (specific competition data is included for the exploratory process only. The goal of modeling in this project is to predict Olympic scores based on competitive history so all Olympic data aside from the target variable will be dropped pre-modeling).\n",
    "\n",
    "### Non-Olympic scores in the 4 year period preceding the Olympics have been averaged together for each record in the following categories:\n",
    "\n",
    "- short program/free program/final event place\n",
    "- short program/free program/final event score\n",
    "- short program/free program/final components score\n",
    "- short program/free program/final elements score\n",
    "- average errors including deductions(falls and/or major error), under rotation jump error, costly jump error, major combination jump error, jump downgrade, illegal element, suspected errors, and all jump errors\n",
    "- average difficult jumping elements including quads, triple axels, and triple triple (note- this accounts for attempted jumps only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68274271",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis & Statistical Testing\n",
    "\n",
    "- Create hypotheses regarding drivers of Olympic Event Scores.\n",
    "- Split data into 3 subsets for proper statistical analysis and modeling.\n",
    "- Use the train data to explore hypotheses.\n",
    "- Visualize bivariate and/or multivariate data and assess hypotheses using statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa995b83",
   "metadata": {},
   "source": [
    "### Hypotheses & Exploration Plan:\n",
    "\n",
    "> Jumping Difficulty- Based on basic domain knowledge, I believe skaters that demonstrate difficult jumping ability in international events will have higher Olympic scores. While triple axels and quadruple jumps are not very common in women's figure skating, the point value for these elements is very high so executing one or more of these jumps in a program can really set the athlete apart. Triple-triple combinations, although much more common, are still not something all women Olympians can do with ease so I am considering it a \"difficult jump\" at this time. I create separate columns for these 3 difficult jumping elements to explore this hypothesis.\n",
    " \n",
    "> USA athletes and technical scores- I hypothesize that USA skaters have lower technical/elements scores, especially compared to Olympic medals. I am curious to see how far behind USA skaters are to the top performers in this category and whether or not there appears to be a trend throughout the seasons.\n",
    " \n",
    "> USA athletes and components scores - Historically, USA skaters have been known to have strong \"presentation.\" Under the former scoring system, the \"presentation score\" was closest to what the components score is currently, yet the components score is calculated with more objective criteria. Do USA athletes have an edge in the components score as they did in the presentation score? While I did not acquire old scores prior to 2004 for this project, I will compare components scores by country groupings to see where USA athletes stand. \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c5f4d",
   "metadata": {},
   "source": [
    "### Splitting Data\n",
    "\n",
    "Splitting data into 3 subsets (train, validate, test) for proper statistical analysis, exploration, modeling, and assessment.\n",
    "- Train: explore features and relationships to target variable, statistical analysis, build models \n",
    "- Validate: evaluate model performance compared to the train dataset, Assess potential overfitting\n",
    "- Test: run only the chosen top performing to ensure model performs as expected on unseen data before employing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split_data(df)\n",
    "# Function that plits data into 3 subsets: train, validate, test. Random state specifying that data is split\n",
    "# with the exact same records when the code is re-run (useful for exploration and modeling, yet\n",
    "# I suggest dropping this when employing the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0670c",
   "metadata": {},
   "source": [
    "### Feature Correlation (contiuous variables) to Olympic event score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['oly_event_final_place', 'oly_short_score', 'oly_short_elements_score', 'oly_short_components_score', 'oly_free_elements_score', 'oly_free_components_score', 'oly_free_score', 'oly_event_score'], axis=1).corrwith(train['oly_event_score'], method='pearson').sort_values().plot(kind='barh', grid=True, figsize=(15,12), color='salmon')\n",
    "plt.title(\"Correlation with target\", fontweight='bold', size=20)\n",
    "plt.xticks(size=12, rotation=90)\n",
    "plt.yticks(size=12)\n",
    "plt.show()\n",
    "# graphs the correlation strength of features to the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e2e33",
   "metadata": {},
   "source": [
    "### Feature Correlation to Olympic Score Analysis\n",
    "Interestingly, most jumping errors do not seem to be highly correlated with Olympic scores. While further analysis is needed, it's possible that taking technical risks could pay off. Actually, suspected errors are positively correlated with Olympic scores. Suspected errors do not include a mandatory deduction, but I'm very curious why we'd see any positive correlation here. Based on this graph, the only specific jumping attribute that shows a useful correlation to Olympic scores is average quad attempts. Very few women figure skaters have attempted quads in international competition and those that have attempted them have tended to be very technically advanced skaters so this correlation is not surprising. If anything, I'd expect the correlation to be higher. The triple axel is another jump that only a handful of advanced women skaters attempt and/or complete so it's surprising that there's such a weak correlation with Olympic scores. However, as mentioned, the advanced jump columns take attempts and not necessarily successful completion into account so it's probable that the correlation would look different if looking at these jumps landed cleanly only. Breaking these features down further in such ways is very possible with advanced (and more timely) data wrangling which I plan on pursuing shortly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66c13c",
   "metadata": {},
   "source": [
    "### Creating Columns to Separate USA athletes for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"top\"] = train[\"country\"].apply(lambda country: explore.top_score(country))\n",
    "#uses pre-defined user function to create a column specifying if the record/skater is from a the USA, a country that\n",
    "#has medaled in Womens Figure Skating Olympics since 2006, or all other countries\n",
    "train[\"usa\"] = train[\"country\"].apply(lambda country: explore.usa_score(country))\n",
    "#uses pre-defined user function to create a column specifying if the record/skater is from a the USA or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4a75d",
   "metadata": {},
   "source": [
    "### Graphing Correlation of Features to Target Variable through the lens of USA/Top Performing Countries/Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092aeb70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X1 = train[['event_final_place', 'event_score', 'short_place', 'short_score', 'short_elements_score',  'short_components_score', 'free_place', 'free_score', 'free_elements_score', 'free_components_score']]\n",
    "#creates df of Average Scores & Placements\n",
    "fig = plt.figure(1, figsize=(16,16))\n",
    "plt.title('Average Scores & Placements Grouped By Top Performing Countries', size=20, pad=40)\n",
    "for i, col in enumerate(X1.columns, 1): #loops through columns in df to plot said columns with target variable\n",
    "    fig.add_subplot(4,3,i)\n",
    "    sns.scatterplot(x=col, y='oly_event_score', data=train, hue='top', palette='gnuplot2_r')\n",
    "    plt.legend(fontsize=8, loc='best')\n",
    "    plt.title(col, size=15)\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.6)\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffc68a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X2 = train[['event_deductions', 'free_deductions', 'short_deductions', 'under_rotations', 'downgrades', 'edge_error', 'combo_no_credit', 'illegal_element', 'jump_errors_all', 'jump_errors_costly', 'suspected_edge_error', 'suspected_rotation_error']]\n",
    "#creates df of Average Jump Errors in non-Olympic Events\n",
    "fig = plt.figure(1, figsize=(16,16))\n",
    "plt.title('Average Jump Errors in non-Olympic Events Grouped By Top Performing Countries', size=20, pad=40)\n",
    "for i, col in enumerate(X2.columns, 1):  #loops through columns in df to plot said columns with target variable\n",
    "    fig.add_subplot(4,3,i)\n",
    "    sns.scatterplot(x=col, y='oly_event_score', data=train, hue='top', palette='gnuplot2_r')\n",
    "    plt.legend(fontsize=8, loc='best')\n",
    "    plt.title('Error Type: ' + col, size=15)\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.6)\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ba70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = train[['triple_triple', 'triple_axel', 'quad']]\n",
    "#creates df of Average Difficult Jumps in non-Olympic Events\n",
    "fig = plt.figure(1, figsize=(18,4))\n",
    "plt.title('Average Difficult Jumps in non-Olympic Events Grouped By Top Performing Countries', size=20, pad=40)\n",
    "for i, col in enumerate(X3.columns, 1): #loops through columns in df to plot said columns with target variable\n",
    "    fig.add_subplot(1,3,i)\n",
    "    sns.scatterplot(x=col, y='oly_event_score', data=train, hue='top', palette='gnuplot2_r')\n",
    "    plt.legend(fontsize=8, loc='best')\n",
    "    plt.title('Error Type: ' + col, size=15)\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.6)\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore.scores_season(train)\n",
    "#pre-defined user function that displays mean scores in dataframes grouped by country data for comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af8584",
   "metadata": {},
   "source": [
    "### Analysis of USA scores vs. Top Scores vs. Other Scores\n",
    "\n",
    "Even excluding Russia, the top performing skaters AND skaters that did not make the Olympic podium have a consistent increase across all categories where the US skaters have not(looking at mean scores). On average, US skaters are very competitive in the program components and short elements scores, but seem to lose with the free elements. One possible explanation could be endurance training. US skaters seem to be competitive in the short program both with elements and program components. This could mean that US skaters don't necessary lack technical abilities, but because the free program is longer and typically has 7 jumping elements (as opposed to 3 in the short program), endurance could possibly explain this. It would be interesting to break down the elements performed in the program and if there is a trend that may give more insight to this theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02850a",
   "metadata": {},
   "source": [
    "### Graphing Relationship of Season to Target Variable through the lens of USA/Top Performing Countries/Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738886d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('Set2', 20)\n",
    "# sets colors for graph\n",
    "sns.lmplot(x='season', y='oly_event_score', data=train, scatter=True, hue='top', col=None, height=5.5, aspect=8.7/5.5)\n",
    "plt.title(\"Olympic Scores Compared to Season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b0dae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explore.plot_scores(train)\n",
    "#pre-defined user function that plots the relationship of the first Olympic season under the IJS scoring system  \n",
    "#and the most recent Olympics to scores grouping by country data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca85903",
   "metadata": {},
   "source": [
    "### Statistical Testing\n",
    "- Utilizing ANOVA and/or T- test to determine if there is a difference between the target variable and country groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_score = train[train.top == 'usa'].oly_event_score\n",
    "top_score = train[train.top == 'top'].oly_event_score\n",
    "other_score = train[train.top == 'other'].oly_event_score\n",
    "#create 3 seperate dfs in preparation for ANOVA test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab170844",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usa_score.var())\n",
    "print(top_score.var())\n",
    "print(other_score.var())\n",
    "#shows variance of target variable in the 3 seperate groupings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1cc53",
   "metadata": {},
   "source": [
    "### 2-sample, independent t-test\n",
    "- Looking at the variances, they are very different, so I will move to a 2-sample, independent t-test comparing one subgroup to all other records.\n",
    "- alpha = .05\n",
    "\n",
    "$H_0$: There is not a noteable difference between mean Olympic scores of USA athletes and all other athletes.\n",
    "\n",
    "$H_a$ : There is a noteable difference between mean Olympic scores of USA athletes and all other athletes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c8570",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05 #sets alpha\n",
    "usa_score = train[train.top == 'usa'].oly_event_score\n",
    "other_score = train[train.top != 'usa'].oly_event_score\n",
    "t, p = stats.ttest_ind(usa_score, other_score, equal_var=False)\n",
    "#runs ind t-test\n",
    "if p > alpha:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e9a51b",
   "metadata": {},
   "source": [
    "$H_0$: There is not a noteable difference between mean Olympic scores of athletes from top performing countries and all other athletes.\n",
    "\n",
    "$H_a$ : There is a noteable difference between mean Olympic scores of athletes from top performing countries and all other athletes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fce8ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_score = train[train.top == 'top'].oly_event_score\n",
    "other_score = train[train.top != 'top'].oly_event_score\n",
    "t, p = stats.ttest_ind(top_score, other_score, equal_var=False)\n",
    "#runs ind t-test\n",
    "if p > alpha:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We reject the null hypothesis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac7fca",
   "metadata": {},
   "source": [
    "$H_0$: There is not a noteable difference between mean Olympic scores of athletes from non-top performing countries nor the USA and all other athletes.\n",
    "\n",
    "$H_a$ : There is a noteable difference between mean Olympic scores of athletes from non-top performing countries nor the USA and all other athletes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58942b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_score = train[train.top == 'other'].oly_event_score\n",
    "top_or_usa_score = train[train.top != 'other'].oly_event_score\n",
    "t, p = stats.ttest_ind(top_or_usa_score, other_score, equal_var=False)\n",
    "#runs ind t-test\n",
    "if p > alpha:\n",
    "    print(\"We fail to reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4135bef8",
   "metadata": {},
   "source": [
    "### T-Test Analysis : \n",
    "-There does appear to be a statistically significant difference of top performing countries to all others and non-top, non-USA to others, but not USA to others. This may be due to the USA performing very medicorely and blending in with others or potentially, this may be due to USA athletes differing greatly in competitiveness from 2006 to 2022.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39344f76",
   "metadata": {},
   "source": [
    "### Pearsons R Correlation Tests\n",
    "- Because there seem to be several continuous features correlated to the target, I am looping through continuous columns to determine which features have a statistically significant correlation with the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0468be7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explore.corr_tests(train)\n",
    "#runs correlation test on all continous features (with the exception of features that are influenced by the target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2c6d6",
   "metadata": {},
   "source": [
    "### Correlation Test Analysis: \n",
    "- These correlation tests are very useful in deciding which features I will use in modeling. I am cutting the statistical significance off at .4 at this time and will go ahead and use all features that have a 40% or greater correlation to the target (minus features that are directly influenced by the target- ie.other portions of the Olympic score) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d040756",
   "metadata": {},
   "source": [
    "### Modeling (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae893ed",
   "metadata": {},
   "source": [
    "- In preparation for modeling, I will reset the index of the 3 dataframes (needed step as there are duplicate names due to some skaters going to more than one Olympics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index()\n",
    "validate = validate.reset_index()\n",
    "test = test.reset_index()\n",
    "#resets index\n",
    "train = train.drop(columns=['index'])\n",
    "validate = validate.drop(columns=['index'])\n",
    "test = test.drop(columns=['index'])\n",
    "#drops unnessary column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286b6c9",
   "metadata": {},
   "source": [
    "- Splitting all 3 datasets into X and y subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['combo_no_credit', 'free_deductions' , 'short_deductions',  'event_deductions', 'under_rotations', 'downgrades' , 'edge_error', 'suspected_edge_error', 'suspected_rotation_error',\n",
    "'illegal_element' ,'jump_errors_all' ,'jump_errors_costly', 'triple_triple', 'triple_axel', 'skater_name','oly_event_final_place', 'oly_short_score', 'oly_short_elements_score',\n",
    "                             'oly_short_components_score', 'oly_free_elements_score', 'oly_free_components_score',\n",
    "                             'oly_free_score', 'oly_event_score', 'top', 'country', 'usa'])\n",
    "# creates dataframe that drops all column except the selected features for modeling\n",
    "y_train = train[['oly_event_score']]\n",
    "# creates dataframe of target variable (y) only\n",
    "\n",
    "X_validate = validate.drop(columns=['combo_no_credit', 'free_deductions' , 'short_deductions',  'event_deductions', 'under_rotations', 'downgrades' , 'edge_error', 'suspected_edge_error', 'suspected_rotation_error',\n",
    "'illegal_element' ,'jump_errors_all' ,'jump_errors_costly', 'triple_triple', 'triple_axel', 'skater_name','oly_event_final_place', 'oly_short_score', 'oly_short_elements_score',\n",
    "                             'oly_short_components_score', 'oly_free_elements_score', 'oly_free_components_score',\n",
    "                             'oly_free_score', 'oly_event_score','country'])\n",
    "y_validate = validate[['oly_event_score']]\n",
    "# repeat above for validate set\n",
    "\n",
    "X_test = test.drop(columns=['combo_no_credit', 'free_deductions' , 'short_deductions',  'event_deductions', 'under_rotations', 'downgrades' , 'edge_error', 'suspected_edge_error', 'suspected_rotation_error',\n",
    "'illegal_element' ,'jump_errors_all' ,'jump_errors_costly', 'triple_triple', 'triple_axel', 'skater_name','oly_event_final_place', 'oly_short_score', 'oly_short_elements_score',\n",
    "                             'oly_short_components_score', 'oly_free_elements_score', 'oly_free_components_score',\n",
    "                             'oly_free_score', 'oly_event_score', 'country'])\n",
    "y_test = test[['oly_event_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac39a34",
   "metadata": {},
   "source": [
    "- Scaling data in prepation for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "# employs the standars scaler\n",
    "scaler.fit(X_train)\n",
    "# inserts the selected features into the scaler\n",
    "\n",
    "X_train = data=scaler.transform(X_train)\n",
    "X_validate = data=scaler.transform(X_validate)\n",
    "X_test = data=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f93fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_validate = pd.DataFrame(X_validate)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "#reassigns dataframes with scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721886f",
   "metadata": {},
   "source": [
    "- Establishing Baseline RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2da0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['pred_mean'] = y_train.oly_event_score.mean()\n",
    "train['pred_mean'] = train.oly_event_score.mean()\n",
    "y_validate['pred_mean'] = y_validate.oly_event_score.mean()\n",
    "y_test['pred_mean'] = y_test.oly_event_score.mean()\n",
    "# calculates mean prior to computing rmse\n",
    "\n",
    "rmse_train = mean_squared_error(y_train.oly_event_score, y_train.pred_mean)**(1/2)\n",
    "rmse_validate = mean_squared_error(y_validate.oly_event_score, y_validate.pred_mean)**(1/2)\n",
    "# computes baseline RMSE for train and validate sets (square root of MSE)\n",
    "\n",
    "print(\"Baseline RMSE\\nTrain/In-Sample: \", round(rmse_train, 2)), \n",
    "print(\"Baseline RMSE\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f9e068",
   "metadata": {},
   "source": [
    "### Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6983c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression(normalize=True)\n",
    "# create the model\n",
    "\n",
    "lm.fit(X_train, y_train.oly_event_score)\n",
    "# fit the model to scaled training data\n",
    "\n",
    "y_train['value_predict_lm'] = lm.predict(X_train)\n",
    "# computes model predictions\n",
    "rmse_train = mean_squared_error(y_train.oly_event_score, y_train.value_predict_lm)**(1/2)\n",
    "# computes model rmse\n",
    "\n",
    "y_validate['value_predict_lm'] = lm.predict(X_validate)\n",
    "rmse_validate = mean_squared_error(y_validate.oly_event_score, y_validate.value_predict_lm)**(1/2)\n",
    "# comutes predictions and rmse with validate data\n",
    "\n",
    "print(\"**OLS Linear Regression Performance**\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", round(rmse_train, 2))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE for OLS using LinearRegression\\nValidation/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4e124",
   "metadata": {},
   "source": [
    "- The linear regression model shows a great reduction in RMSE, but I am skeptical of overfitting here. Especially with a somewhat small dataset, I'm really looking for similar RMSE values for in sample and out of sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47925e",
   "metadata": {},
   "source": [
    "### Lasso Lars Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb91d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lars = LassoLars(alpha=1)\n",
    "# creates the model\n",
    "\n",
    "lars.fit(X_train, y_train.oly_event_score)\n",
    "# fit the model to scaled training data\n",
    "\n",
    "y_train['pred_lars'] = lars.predict(X_train)\n",
    "# computes model predictions\n",
    "rmse_train = mean_squared_error(y_train.oly_event_score, y_train.pred_lars)**(1/2)\n",
    "# computes model rmse\n",
    "\n",
    "y_validate['pred_lars'] = lars.predict(X_validate)\n",
    "rmse_validate = mean_squared_error(y_validate.oly_event_score, y_validate.pred_lars)**(1/2)\n",
    "# comutes predictions and rmse with validate data\n",
    "\n",
    "print(\"**LARS Performance**\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE for Lars\\nTraining/In-Sample: \", round(rmse_train, 2))\n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE for Lars\\nOut-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2280a",
   "metadata": {},
   "source": [
    "- The lasso lars regression model looks great when it comes to overfitting. This model performs better than baseline and should definitely be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3ffd0",
   "metadata": {},
   "source": [
    "### Generalized Linear Model : Tweedie Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0da791",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = TweedieRegressor(power= 2, alpha=3)\n",
    "# creates the model\n",
    "\n",
    "glm.fit(X_train, y_train.oly_event_score)\n",
    "# fit the model to scaled training data\n",
    "\n",
    "y_train['pred_value_glm'] = glm.predict(X_train)\n",
    "# computes model predictions\n",
    "rmse_train = mean_squared_error(y_train.oly_event_score, y_train.pred_value_glm)**(1/2)\n",
    "# computes model rmse\n",
    "\n",
    "y_validate['pred_value_glm'] = glm.predict(X_validate)\n",
    "rmse_validate = mean_squared_error(y_validate.oly_event_score, y_validate.pred_value_glm)**(1/2)\n",
    "# comutes predictions and rmse with validate data\n",
    "\n",
    "print(\"**Generalized Linear Model Performance**\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE for GLM /In-Sample: \", round(rmse_train, 2)), \n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE for GLM \\nValidation/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6f013",
   "metadata": {},
   "source": [
    " - The GLM Tweedie Regressor has the lowest RMSE values collectively for in sample and out of sample data. There is a difference of 2 between the RMSE values so I am considering whether or not overfitting is present here. Because there is also a difference of 2 in the baseline RMSEs of train and validate, I think it's reasonable to accept this slight difference as normal and not likely due to overfitting. Taking all into consideration, I am choosing the GLM model as the superior model at this time. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7897a0",
   "metadata": {},
   "source": [
    "### Chosen Model: GLM Tweedie Regressor \n",
    "- Running model with Test data to confirm performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bcfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['pred_value_glm'] = glm.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test.oly_event_score, y_test.pred_value_glm)**(1/2)\n",
    "\n",
    "print(\"**Generalized Linear Model Performance on Test Data**\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"RMSE : Test Data \\nTesting/Out-of-Sample: \", round(rmse_test, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becf06ac",
   "metadata": {},
   "source": [
    "- The RMSE of test is in the middle of that of train and validate which is a great sign regarding the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935bde67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predictions'] = glm.predict(X_train)\n",
    "validate['predictions'] = glm.predict(X_validate)\n",
    "test['predictions'] = glm.predict(X_test)\n",
    "#creates columns on dataframes with glm predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279caa3a",
   "metadata": {},
   "source": [
    "### Plotting Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36684cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(train.oly_event_score, color='red', label='Actual')\n",
    "ax1.legend()\n",
    "\n",
    "ax1.plot(train.predictions , color='purple', label='Predicted_GLM')\n",
    "ax1.legend()\n",
    "\n",
    "ax1.plot(train.pred_mean , color='green', label='Baseline')\n",
    "ax1.legend()\n",
    "plt.title('Model Predictions vs. Actual and Baseline: Train')\n",
    "plt.show()\n",
    "\n",
    "fig, ax2 = plt.subplots()\n",
    "ax2.plot(validate.oly_event_score, color='red', label='Actual')\n",
    "ax2.legend()\n",
    "\n",
    "ax2.plot(validate.predictions , color='purple', label='Predicted_GLM')\n",
    "ax2.legend()\n",
    "\n",
    "ax2.plot(y_validate.pred_mean , color='green', label='Baseline')\n",
    "ax2.legend()\n",
    "plt.title('Model Predictions vs. Actual and Baseline: Validate')\n",
    "plt.show()\n",
    "\n",
    "fig, ax3 = plt.subplots()\n",
    "ax3.plot(test.oly_event_score, color='red', label='Actual')\n",
    "ax3.legend()\n",
    "\n",
    "ax3.plot(test.predictions , color='purple', label='Predicted_GLM')\n",
    "ax3.legend()\n",
    "\n",
    "ax3.plot(y_test.pred_mean , color='green', label='Baseline')\n",
    "ax3.legend()\n",
    "plt.title('Model Predictions vs. Actual and Baseline: Test')\n",
    "plt.show()\n",
    "#plots baseline, actual, and model predictions of all 3 dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c51c1",
   "metadata": {},
   "source": [
    "- this graph demonstrates that the modeling process was successful and is exponentially better than baseline predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3798720",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- I successfully created a machine learning regression model that improves predicted Olympic scores of women figure skaters with a 50% improvement from baseline predictions.\n",
    "\n",
    "- My analysis indicates that the top drivers of Olympic Scores are:\n",
    "     > - Athlete's 4 year international competitive history preceding the Olympics\n",
    "     > - Short Program Event Scores (components and elements)\n",
    "     > - Free Program Event Scores (components and elements)\n",
    "     > - Event placements\n",
    "     > - competitive season\n",
    "\n",
    "- My data exploration revealed that USA athletes' scores are lower than desired due to :\n",
    "     > - USA athletes have a lower margin of score improvement over the last 15 years compared to non-USA athletes\n",
    "     > - The elements portion of free program shows the worst margin of improvement for USA athletes \n",
    "     > - USA athletes still slightly outscore non-USA athletes in the components score, but if the trend over the last 15 years continues, USA athletes may fall behind in this category as well\n",
    "     > - USA athletes' element scores seem to be more problematic in the free program. Because the free program is longer than the short program, lack of athletic endurance is one possible explanation to explain this discrepancy.\n",
    "\n",
    "- Interestingly, the skater's 4 year average amount of technical jumping errors did not seem to be a factor contributing to Olympic scores. \n",
    "\n",
    "### Next Steps \n",
    "\n",
    "- I believe this project demonstrates great promise for the use of data science in improving training strategies and competition outcomes in US Figure Skating and I'm very excited to uncover this potential.\n",
    "\n",
    "- Next, I'll expand on this project by undertaking a similar exploration and modeling approach, but use data that is more training based instead of just competition data (ie. skaters' coaching team, location, training methods, etc.)\n",
    "\n",
    "- My ultimate goal is to build a model for coaches and skaters that will take into account a skater's element consistency and supply \"ideal program content\" - the elements that a skater should put in the program to maximize scoring potential based on a reasonable bar set from previous accuracy."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
